{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdlenvconda29b652f870674263985143dd5e5a7bc4",
   "display_name": "Python 3.7.6 64-bit ('DLENV': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apply Model to some inputs Learn how:\n",
    "\n",
    "Load a saved Model\n",
    "Select inputs\n",
    "Apply Model to inputs (Predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy: Numeric library\n",
    "import numpy as np \n",
    "#graphics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#tensorflow: use some TF tools\n",
    "import tensorflow as tf\n",
    "#Keras: Deep learning API. In TF 2.x, it is included in TF\n",
    "from tensorflow import keras\n",
    "#Import Dense layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "#Optimizers: SGD (Stochastic Gradien Descent)\n",
    "#from tensorflow.keras.optimizers import SGD as sgd\n",
    "\n",
    "#import data set MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some verifications"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import MNIST data set\n",
    "60000 training examples\n",
    "10000 validation examples\n",
    "1 example = 28 * 28 matrix (image with 28 * 28 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process & Prepare data\n",
    "Flattening Input data:\n",
    "Input data (x_train[i]) should be a vector of real values\n",
    "- From shape (60000, 28, 28) to shape (60000, 28 * 28)\n",
    "- Convert to float32 (default is uint8, which python will convert to float64) (flaot 32 will take less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numpy reshape\n",
    "x_train = np.reshape(X_train, (60000, 28 * 28)).astype('float32')\n",
    "x_valid = np.reshape(X_valid, (10000, 28 * 28)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare Data (2)\n",
    "divide by 255, so the values will range from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train)\n",
    "x_train /=  255\n",
    "x_valid /=  255"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#load Model\n",
    "folder = \"logs/crossEntropyReLu2LayersWI/20200229-180923/\"\n",
    "model = load_model(folder + 'model_all.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Select some inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "indexes: array([1698,  124, 8218, 2619, 7898, 2269, 8280, 3134,  460, 1524, 8236,\n       5807, 7031, 3437, 1379,  869, 4763, 2987,  117, 3001, 5714, 4193,\n       1426, 5525, 1844, 6694, 7004, 7429, 5357,  900, 2992, 3298, 8766,\n       5065, 6357, 5097, 5293,  605, 6369, 9692, 5542, 5860, 6456,  613,\n       7253, 1970, 3961, 5503, 5022,  810, 4596, 3803, 6969, 8095,  724,\n       3360, 4451,  109, 4561, 5672, 6691, 5962, 5127, 4034, 3064, 1400,\n       2436, 2825, 7254,  820, 7738, 7067, 4147, 8707, 2162, 6196, 2154,\n        176, 6025, 4768, 9645, 5220, 4804, 8621, 4969, 7335,  150,  980,\n       5120, 6261, 2655, 5679, 2802, 6205, 5900, 9208, 3693, 3443,  350,\n       7116])\n(100, 784)\n(100,)\n"
    }
   ],
   "source": [
    "#print(x_train[0])\n",
    "size = 100\n",
    "indexes = np.random.randint(0, y_valid.size-1, size=size)\n",
    "tf.print(\"indexes:\", indexes)\n",
    "x = np.array([x_valid[i] for i in indexes])\n",
    "X = np.array([X_valid[i] for i in indexes])\n",
    "y = np.array([y_valid[i] for i in indexes])\n",
    "tf.print(x.shape)\n",
    "tf.print(y.shape)\n",
    "# x = np.array([x_train[0], x_train[1], x_train[4566]])\n",
    "# y = np.array([y_train[0], y_train[1], y_train[4566]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#predict\n",
    "y_predicted = model.predict_classes(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print Prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print prediction results\n",
    "#tf.print(\"y:\", y)\n",
    "#tf.print(\"predicted classes\", y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "False\nNot predicted indexes: [ 8 19 39]\nNot predicted y: [5, 9, 9]\nNot predicted y_predicted: [9, 8, 7]\n"
    }
   ],
   "source": [
    "#check if prediction is valid\n",
    "comparison = y == y_predicted\n",
    "equal_arrays = comparison.all()\n",
    "\n",
    "#prints True if All is OK\n",
    "print(equal_arrays)\n",
    "\n",
    "#print not predicted indexes\n",
    "diff = y - y_predicted\n",
    " \n",
    "indexes_false = np.array([i for i in np.arange(diff.size) if diff[i] != 0])\n",
    "print(\"Not predicted indexes:\", indexes_false)\n",
    "print(\"Not predicted y:\", [y[i] for i in indexes_false])\n",
    "print(\"Not predicted y_predicted:\", [y_predicted[i] for i in indexes_false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy =  0.97\n"
    }
   ],
   "source": [
    "#Accuracy\n",
    "acc =  1- indexes_false.size/size\n",
    "print(\"Accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 8, 19, 39])"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "np.array(indexes_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"90.9pt\" version=\"1.1\" viewBox=\"0 0 265.5 90.9\" width=\"265.5pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 90.9 \r\nL 265.5 90.9 \r\nL 265.5 -0 \r\nL 0 -0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#p900afa033c)\">\r\n    <image height=\"77\" id=\"image886ba8e1eb\" transform=\"scale(1 -1)translate(0 -77)\" width=\"77\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAE0AAABNCAYAAADjCemwAAAABHNCSVQICAgIfAhkiAAAAvtJREFUeJztm71LsmEYxU9pYl8QoiDhllMI0RJIECk1+zfo0NDSHxA4tDU2tDgWNPQxRGC0ubSEVtYmtBs0hEsQlE1e7yNSL558fJ7g/KbD/fhxeTyXt9737Ui73W5D9MWo1wX8RWQaQdDrAgDg+vra9MrKCgBgY2PDxnZ2dkzHYrHhFfYNShqBTCMY8Wr2vLu7M725uWn65uam57Zzc3Omb29vTU9NTblU3c8oaQSeTQTn5+em7+/vTWezWQDdSXx6ejJ9fHxsulAouFnityhpBDKNwLOJoNFomB4d/ffeJZNJAN0tu7W1ZXp2dtb04eEhACAYHO6njJJGINMIPGvPfqjVaqaXlpZMt1otAMDk5ORQ61HSCGQagUwjkGkEMo1AphHINAJfLHf/j7e3N9OdVRAAGBsb86IcJY1BphH8ifbc3d01vba2ZjoUCnlRjpLGINMIfNuez8/Ppp07VLlczotyulDSCHybtP39fdMvLy+m/bD8p6QRyDSCoSx3v76+AujeAP6O09NTAMDR0ZGNRSIR085dqunp6UGV2BdKGoFMI3Bt9uy0JACsrq4CAB4fH6nHcv6M8qolnShpBDKNwLX2dLZROBz+8bbRaNR0qVQCAMzPz9tY53yHX1DSCFz7nvbw8GB6cXGx57rzpFC1WjW9sLDgRjkDRUkjkGkErk0EzpM84+PjALp3lT4/P00vLy+bLpfLALo//CcmJkzPzMwMvtg+UdIIZBrBUFY58vk8AODg4IC6fzweN53JZHqub29vm04kEqbd+smlpBHINIKhtGdn1iwWiza2t7dn+uPjY2DP5Zx10+m06c6ewyDO5yppBJ6d7q5UKqavrq56rjebTdPsBOKkXq8DAFKp1K8fS0kjkGkEvv3zhXNyeH9/N31ycmL64uICAHB2dmZjzpdzeXlpen19HQAQCAR+XZuSRiDTCHzbnn5GSSOQaQQyjUCmEcg0AplGINMIZBqBTCOQaQQyjUCmEcg0AplGINMIZBqBTCOQaQRf/8HCRrrdre4AAAAASUVORK5CYII=\" y=\"-6.7\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g clip-path=\"url(#pf85e849717)\">\r\n    <image height=\"77\" id=\"imageeb5efe9aad\" transform=\"scale(1 -1)translate(0 -77)\" width=\"77\" x=\"94.5\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAE0AAABNCAYAAADjCemwAAAABHNCSVQICAgIfAhkiAAAA+NJREFUeJztm8srbW8Yx7/nF5GIhInLQBmhEOUWEcVEMjUSUQb8AQZEogyUgYEJAwMjZsqAch0gKXcDihgoyT0UZ7S+v2e3O87Zz177op7P6NuTvdbTt+9rve963/Xr6+vrC4ZP/BfqBn4iZpoCM02BmabATFMQEeoG/oXKykrq9fV16qKiIgDA4uIiazExMQHvx5KmIGyTtrOzQ722tkZdUlJCnZqaCgDY3t5mraKiIuC9WdIUmGkKfoXrMqq2tpZ6aWmJemtri7qgoCCoPTlY0hSYaQrC9umZnZ1NfXFxQZ2XlxeKdjywpCkw0xSE7fAsKyujnpqaor66uqJOT08PZkvEkqYgbJN2cHAQ6hb+iCVNgZmmwNVl1OfnJ3VHRwf1yckJAGBkZIQ1uQSKjIz0upacj72/v1MfHh6606wfWNIUmGkKXH16dnd3U09OTlKnpKQA8Jx7ySEpX1dHR0cDANLS0lg7Oztzs02/saQpMNMUuPr0lO/v5ZByJqobGxus9ff3U+/u7n57XWfIAkBnZyf1wMAAACAqKkrZsQ5LmgJXHwQytPIffVJSEgCgoaGBtZqaGuqenh7qsbExr+s+Pz9Ty3laRERoVoGWNAVmmgJX852cnEwtN3Cdzd7y8nLW5PGB0dFR6sLCQgBAW1sba3IZdXp6Sv36+goAiI2N9bt3X7CkKTDTFLg6PJ15EwAsLCyortHc3AwAOD8/Z623t5dazv+enp4A2PD8EZhpCgJ2liMhIYG6sbERgOeu0t94eXmhrq6uppZP5ZycHADA8PAwa3V1dT736iuWNAUBW4c0NTVRT09PA/BcLmVlZX37ezmPm5+fp5Z7nfv7+wCA6+tr/5r1EUuaAjNNQcCG58TEBPXNzQ0AoK+vj7WhoSHqjIyMb6+VmJhILd+91dfX+9umCkuaAjNNQVDO3I6PjwMAurq6WIuLi6O+u7tTXdfZkD46OmJtZWWF+v7+ntr5m+LiYtW9JJY0BWaagqAMz4eHBwD/f8sEAJeXl9THx8fUf3uSSj4+PgAAMzMzrDlLNsDzm6q9vT0AwPLyMmulpaX/fC+JJU1BUD++kHMsuTMlX2e3trZ6/S4+Pp66vb2d2jml9Pj4yJrcT93c3KQeHBz0uq8WS5oCM01ByL6Nur29pf7TcQYH2aLc8Xp7ewPgOTzz8/OpV1dXqeXRBn+xpCkw0xSExaeL8tX23NwcAGB2dtarBgCZmZnULS0tAICqqirWcnNzqeVSzU0saQrMNAVhMTx/GpY0BWaaAjNNgZmmwExTYKYpMNMUmGkKzDQFZpoCM02BmabATFNgpikw0xT8BnpwIFgRnKMoAAAAAElFTkSuQmCC\" y=\"-6.7\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_3\">\r\n   <g clip-path=\"url(#p690ed44f91)\">\r\n    <image height=\"77\" id=\"image5c75de5ce8\" transform=\"scale(1 -1)translate(0 -77)\" width=\"77\" x=\"181.8\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAE0AAABNCAYAAADjCemwAAAABHNCSVQICAgIfAhkiAAAA8NJREFUeJztm8srrVEYxp/tkkuUUgaEEUZkxACbmQnKTCgGykQGlIEikTIwMZHMUKLkL5BbDJQSRSgSGRGR3MI+g9N6rJ19Trz2Xj71/ka/3tosj3f5vnXhCwQCAShfIuqnB/Ab0dAEaGgCNDQBGpqAGJff7Pz8nH50dEQ/PDykJyUlAQDq6urcDeyLaKcJcNppGRkZIf3u7o7e2NgIAEhPT2fN7/c7GN3n0U4ToKEJ8HltGXV6egoAmJubY629vZ0eE+P0L0pItNMEaGgCfr7XATw8PNCHhoYAAPv7+6zl5ubSq6qq3A3sH2inCdDQBHhiekZFvf/uzFScn59nrbW1lW4vv+Lj4x2M7iPaaQI80WlxcXH05ORkAEBNTQ1r9qvk1dUV3V5quUQ7TYCGJsBzy6jNzU0AQFFREWuZmZl0+/0tISHB3cAstNMEaGgCPDc9Hx8fAQRvUl5fX9P7+vrovb29zsZlo50mQEMT4LnpaRgeHqZ3dXXR09LS6GdnZwCA2NhYdwODdpoIz3aafRZaWFhIt/feTk5OAADZ2dnOxgVop4nQ0AR4Ynrah8XmWoLNzMwMvb6+nm6WWmtra6y5OK3SThOgoQlwOj23trboIyMj9NXVVfr29vbfgfl8rL2+vtJLS0vpZlpPTk6yVlZWFsYRh0Y7TYCGJsDpGcHs7CzdfmKOjo7SzQnT4uIia5eXl/Td3V36wMAAAGBsbIw1nZ4exWmnZWVl0ZeWlugVFRV0s/iurKxkbXx8nG4vqXp6egAAtbW1rL28vNAj9c6mnSZAQxPgdHo2NTXR7Wlk3s0AIC8vDwCQkpLCWktLC31iYuLD1z0+Pqbv7e3RCwoKvjni0GinCdDQBIR1GfX09EQ3d2cBICcn57+f29nZoS8vLwMIvmdrs76+Ti8vLwcAvL29sdbQ0ECfmpr6xKi/jnaaAA1NQFifnvb0tF9COzo6AAD9/f2s2bsYFxcX9I2NDQDBT1T7KVhSUkI3uyb2vY/Ozk75D/BJtNMEhLXTEhMT6dXV1fTBwUEAwTezi4uL6Xb33NzcAACam5tZa2tro5v/nQKA1NRUAEB3dzdrdodHCu00ARqagIhtd9/e3tLNMic/P5+16OjokJ8LtYVt3t0A4P7+nr6ysgLg/XoCELz8ihTaaQI0NAFhnZ7mQh4ALCws0CX/z/T8/Ey372pMT0/TDw4OAATvguhhsUfR0AR44i7Hb0M7TYCGJkBDE6ChCdDQBGhoAjQ0ARqaAA1NgIYmQEMToKEJ0NAEaGgCNDQBfwCssBwLygx5DwAAAABJRU5ErkJggg==\" y=\"-6.7\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p900afa033c\">\r\n   <rect height=\"76.5\" width=\"76.5\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pf85e849717\">\r\n   <rect height=\"76.5\" width=\"76.5\" x=\"94.5\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p690ed44f91\">\r\n   <rect height=\"76.5\" width=\"76.5\" x=\"181.8\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "text/plain": "<Figure size 360x360 with 3 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for k in  np.arange(np.array(indexes_false).size):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X[indexes_false[k]], cmap=\"Greys\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "End"
   ]
  }
 ]
}