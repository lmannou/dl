{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601492012453",
   "display_name": "Python 3.7.6 64-bit ('DLENV': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(5.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=34, shape=(), dtype=float32, numpy=125.0>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=40, shape=(), dtype=float32, numpy=75.0>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=168, shape=(), dtype=float32, numpy=108.0>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "x = tf.Variable(6.0, trainable=True)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**3\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=266, shape=(), dtype=float32, numpy=108.0>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "x = tf.Variable(6.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**3\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None\n"
    }
   ],
   "source": [
    "x = tf.Variable(3.0, trainable=True)\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    y = x**3\n",
    "\n",
    "print(tape.gradient(y, x)) # -> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(27.0, shape=(), dtype=float32)\n"
    }
   ],
   "source": [
    "x = tf.Variable(3.0, trainable=True)\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    tape.watch(x)\n",
    "    y = x**3\n",
    "\n",
    "print(tape.gradient(y, x)) # -> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "GradientTape.gradient can only be called once on non-persistent tapes.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a7a0c496eca2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\DLENV\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \"\"\"\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       raise RuntimeError(\"GradientTape.gradient can only be called once on \"\n\u001b[0m\u001b[0;32m    966\u001b[0m                          \"non-persistent tapes.\")\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: GradientTape.gradient can only be called once on non-persistent tapes."
     ]
    }
   ],
   "source": [
    "# Cannot rerun (not set as persistent)\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "18.0\n"
    }
   ],
   "source": [
    "# Higher-Order Derivatives\n",
    "x = tf.Variable(3.0, trainable=True)\n",
    "with tf.GradientTape() as tape1:\n",
    "    with tf.GradientTape() as tape2:\n",
    "        y = x ** 3\n",
    "    order_1 = tape2.gradient(y, x)\n",
    "order_2 = tape1.gradient(order_1, x)\n",
    "\n",
    "print(order_2.numpy()) # -> 18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12.0\n12.0\n"
    }
   ],
   "source": [
    "a = tf.Variable(6.0, trainable=True)\n",
    "b = tf.Variable(2.0, trainable=True)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y1 = a ** 2\n",
    "    y2 = b ** 3\n",
    "                                                                                                                                                                                                                                                                                                                                                \n",
    "print(tape.gradient(y1, a).numpy())\n",
    "print(tape.gradient(y2, b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12.0\n12.0\n"
    }
   ],
   "source": [
    "print(tape.gradient(y1, a).numpy())\n",
    "print(tape.gradient(y2, b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=358, shape=(), dtype=float32, numpy=108.0>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x = tf.Variable(6.0)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y = x**3\n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=376, shape=(), dtype=float32, numpy=108.0>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    " \n",
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=7.0>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "x.assign(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: id=397, shape=(), dtype=float32, numpy=108.0>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "48.0\n"
    }
   ],
   "source": [
    "x = tf.Variable(4.0, trainable=True)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**3\n",
    "    with tape.stop_recording():\n",
    "        print(tape.gradient(y, x).numpy()) # -> 27.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12.0\n12.0\n2.0\n(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=6.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>)\n"
    }
   ],
   "source": [
    "a = tf.Variable(6.0, trainable=True)\n",
    "b = tf.Variable(2.0, trainable=True)\n",
    "c = tf.Variable(3.0, trainable=True)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y1 = a ** 2\n",
    "    with tape.stop_recording():\n",
    "        print(tape.gradient(y1, a).numpy())\n",
    "    \n",
    "    y2 = b ** 3\n",
    "    with tape.stop_recording():\n",
    "        print(tape.gradient(y2, b).numpy())\n",
    "    y3 = 2 * c\n",
    "    with tape.stop_recording():\n",
    "        print(tape.gradient(y3, c).numpy())\n",
    "    print(tape.watched_variables())"
   ]
  },
  {
   "source": [
    "Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss(real_y, pred_y):\n",
    "    return tf.abs(real_y - pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "x_train = np.asarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y_train = np.asarray([i*10+5 for i in x_train]) # y = 10x+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.6450149>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.98859453>)"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "# Trainable variables\n",
    "a = tf.Variable(random.random(), trainable=True)\n",
    "b = tf.Variable(random.random(), trainable=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.67666644>,\n <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.25877672>)"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Make prediction\n",
    "        pred_y = a * real_x + b\n",
    "        # Calculate loss\n",
    "        reg_loss = loss(real_y, pred_y)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    a_gradients, b_gradients = tape.gradient(reg_loss, (a, b))\n",
    "\n",
    "    # Update variables\n",
    "    a.assign_sub(a_gradients * 0.001)\n",
    "    b.assign_sub(b_gradients * 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100000):\n",
    "    step(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y ≈ 9.999174118041992x + 4.9906325340271\n"
    }
   ],
   "source": [
    "print(f'y ≈ {a.numpy()}x + {b.numpy()}')"
   ]
  },
  {
   "source": [
    "Polynomial regression\n",
    "Exemple: y = a * x**2 + b * x + c"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "x_train = np.arange(10.0)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([  2.,  16.,  46.,  92., 154., 232., 326., 436., 562., 704.])"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "y_train = 8 * x_train **2 + 6 * x_train + 2\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init variables : random\n",
    "a = tf.Variable(np.random(), trainable=True)\n",
    "b = tf.Variable(np.random(), trainable=True)\n",
    "c = tf.Variable(np.random(), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 using Gradient Tap\n",
    "learning_rate = 0.001\n",
    "def step2(x_real, y_real):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # calculate prediction\n",
    "        y_predicted = a * x_real**2 + b * x_real + c\n",
    "        # get loss \n",
    "        loss_value = loss(y_real, y_predicted)\n",
    "\n",
    "        # Get loss function gradients with respect to a, b and c\n",
    "    loss_gradient_a, loss_gradient_b, loss_gradient_c = tape.gradient(loss_value, (a, b, c))\n",
    "\n",
    "    # Next parameters values\n",
    "    a.assign_sub(loss_gradient_a * learning_rate)\n",
    "    b.assign_sub(loss_gradient_b * learning_rate)\n",
    "    c.assign_sub(loss_gradient_c * learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training \n",
    "for _ in range(20000):\n",
    "    step2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "y = 7.996129035949707 x**2 + 5.667584419250488 x + 1.9999451637268066\n"
    }
   ],
   "source": [
    "print(f'y = {a.numpy()} x**2 + {b.numpy()} x + {c.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}