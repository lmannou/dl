{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdlenvconda29b652f870674263985143dd5e5a7bc4",
   "display_name": "Python 3.7.6 64-bit ('DLENV': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First very simple Dense network, with 1 hidden layer.\n",
    "Start from here to improve the model in later iterations\n",
    "2 layers:\n",
    "- one hiden layer : 64 units, sigmoid\n",
    "- Outputlayer : 10 units, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy: Numeric library\n",
    "import numpy as np \n",
    "#graphics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#tensorflow: use some TF tools\n",
    "import tensorflow as tf\n",
    "#Keras: Deep learning API. In TF 2.x, it is included in TF\n",
    "from tensorflow import keras\n",
    "#Import Dense layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "#Optimizers: SGD (Stochastic Gradien Descent)\n",
    "#from tensorflow.keras.optimizers import SGD as sgd\n",
    "\n",
    "#import data set MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF\n",
    "print(np.random.uniform())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import MNIST data set\n",
    "60000 training examples\n",
    "10000 validation examples\n",
    "1 example = 28 * 28 matrix (image with 28 * 28 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process & Prepare data\n",
    "Flattening Input data:\n",
    "Input data (x_train[i]) should be a vector of real values\n",
    "- From shape (60000, 28, 28) to shape (60000, 28 * 28)\n",
    "- Convert to float32 (default is uint8, which python will convert to float64) (flaot 32 will take less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.reshape(60000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numpy reshape\n",
    "x_train = np.reshape(x_train, (60000, 28 * 28)).astype('float32')\n",
    "x_valid = np.reshape(x_valid, (10000, 28 * 28)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare Data (2)\n",
    "divide by 255, so the values will range from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train)\n",
    "x_train /=  255\n",
    "x_valid /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare labels (y_train and y_valid)\n",
    "y_train[i] is given as a number (0, 9). We have 10 possible values. \n",
    "Convert to one-hot format:\n",
    "0 => [1, 0, 0, 0, 0,0, 0,0, 0,0]\n",
    "1 => [0, 1, 0, 0, 0,0, 0,0, 0,0]\n",
    "9 => [0, 0, 0, 0, 0,0, 0,0, 0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "print(y_train[0])\n",
    "\n",
    "print(y_valid[0])\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
    "print(y_valid[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Neural Network Architecture\n",
    "Using Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential: model of type sequential (layer n can pass information only to layer n+1)\n",
    "model = Sequential()\n",
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define activations\n",
    "sigmoid = keras.activations.sigmoid\n",
    "softmax = keras.activations.softmax\n",
    "\n",
    "#define loss function\n",
    "loss = keras.losses.mean_squared_error\n",
    "\n",
    "#define metrics\n",
    "metrics = [keras.metrics.Accuracy()]\n",
    "\n",
    "#define optimizer\n",
    "sgd=keras.optimizers.SGD()\n",
    "#Print default learning rate\n",
    "tf.print(sgd.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define First layer\n",
    "inputSize = 28 * 28 # size of input vector\n",
    "nbUnits = 64 #Number of input layer units (artificial neuron)\n",
    "firstLayer = Dense(nbUnits, activation=  sigmoid, input_shape=(inputSize,))\n",
    "model.add(firstLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Output layer\n",
    " \n",
    "outputUnits = 10 #Number of output layer units (artificial neuron)\n",
    "# output shape will be inferred\n",
    "outputLayer = Dense(outputUnits, activation=  softmax)\n",
    "model.add(outputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile Model\n",
    "model.compile(loss=loss, \n",
    "         optimizer=sgd,\n",
    "         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os \n",
    "import datetime\n",
    "if not os.path.exists('logs/base'):\n",
    "   os.mkdir('logs/base')\n",
    "log_dir = \"logs/base/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(log_dir)\n",
    "os.mkdir(log_dir)\n",
    " \n",
    "tensorBoard = TensorBoard(log_dir, histogram_freq=1,profile_batch = 100000000)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "history = model.fit(x_train, y_train, batch_size= batch_size, epochs = nb_epoch, verbose=1, validation_data=(x_valid, y_valid),\n",
    "callbacks=[tensorBoard])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Display Model using SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With 100 epochs, this basic network seems pretty good, with minimal optimization, the accuracy is above 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "End"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualize "
   ]
  }
 ]
}