{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdlenvconda29b652f870674263985143dd5e5a7bc4",
   "display_name": "Python 3.7.6 64-bit ('DLENV': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First very simple Dense network, with no hidden layer.\n",
    "Start from here to improve the model in later iterations\n",
    "2 layers:\n",
    "- Input: 64 units, sigmoid\n",
    "- Output: 10 units, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy: Numeric library\n",
    "import numpy as np \n",
    "#graphics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#tensorflow: use some TF tools\n",
    "import tensorflow as tf\n",
    "#Keras: Deep learning API. In TF 2.x, it is included in TF\n",
    "from tensorflow import keras\n",
    "#Import Dense layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "#Optimizers: SGD (Stochastic Gradien Descent)\n",
    "#from tensorflow.keras.optimizers import SGD as sgd\n",
    "\n",
    "#import data set MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.7282150018414834\n"
    }
   ],
   "source": [
    "#TF\n",
    "print(np.random.uniform())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import MNIST data set\n",
    "60000 training examples\n",
    "10000 validation examples\n",
    "1 example = 28 * 28 matrix (image with 28 * 28 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 28, 28)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000,)\n"
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(28, 28)\n"
    }
   ],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[5 0 4 ... 5 6 8]\n60000\n"
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(10000, 28, 28)\n(10000,)\n"
    }
   ],
   "source": [
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process & Prepare data\n",
    "Flattening Input data:\n",
    "Input data (x_train[i]) should be a vector of real values\n",
    "- From shape (60000, 28, 28) to shape (60000, 28 * 28)\n",
    "- Convert to float32 (default is uint8, which python will convert to float64) (flaot 32 will take less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.reshape(60000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numpy reshape\n",
    "x_train = np.reshape(x_train, (60000, 28 * 28)).astype('float32')\n",
    "x_valid = np.reshape(x_valid, (10000, 28 * 28)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 784)\n(10000, 784)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare Data (2)\n",
    "divide by 255, so the values will range from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train)\n",
    "x_train /=  255\n",
    "x_valid /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare labels (y_train and y_valid)\n",
    "y_train[i] is given as a number (0, 9). We have 10 possible values. \n",
    "Convert to one-hot format:\n",
    "0 => [1, 0, 0, 0, 0,0, 0,0, 0,0]\n",
    "1 => [0, 1, 0, 0, 0,0, 0,0, 0,0]\n",
    "9 => [0, 0, 0, 0, 0,0, 0,0, 0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n7\n[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "print(y_train[0])\n",
    "\n",
    "print(y_valid[0])\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
    "print(y_valid[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Neural Network Architecture\n",
    "Using Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_12\", \"layers\": []}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential: model of type sequential (layer n can pass information only to layer n+1)\n",
    "model = Sequential()\n",
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x000001448A142888>\n"
    }
   ],
   "source": [
    "#Define activations\n",
    "sigmoid = keras.activations.sigmoid\n",
    "softmax = keras.activations.softmax\n",
    "\n",
    "#define loss function\n",
    "loss = keras.losses.mean_squared_error\n",
    "\n",
    "#define metrics\n",
    "metrics = [keras.metrics.Accuracy()]\n",
    "\n",
    "#define optimizer\n",
    "sgd=keras.optimizers.SGD()\n",
    "print(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Input layer\n",
    "inputSize = 28 * 28 # size of input vector\n",
    "inputUnits = 64 #Number of input layer units (artificial neuron)\n",
    "inputLayer = Dense(inputUnits, activation=  sigmoid, input_shape=(inputSize,))\n",
    "model.add(inputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Output layer\n",
    " \n",
    "outputUnits = 10 #Number of output layer units (artificial neuron)\n",
    "# output shape will be inferred\n",
    "outputLayer = Dense(outputUnits, activation=  softmax)\n",
    "model.add(outputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile Model\n",
    "model.compile(loss=loss, \n",
    "         optimizer=sgd,\n",
    "         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_17 (Dense)             (None, 64)                50240     \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/100\n60000/60000 [==============================] - 2s 26us/sample - loss: 0.0937 - accuracy: 0.0817 - val_loss: 0.0927 - val_accuracy: 0.0755\nEpoch 2/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0921 - accuracy: 0.0725 - val_loss: 0.0916 - val_accuracy: 0.0748\nEpoch 3/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0912 - accuracy: 0.0754 - val_loss: 0.0909 - val_accuracy: 0.0800\nEpoch 4/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0906 - accuracy: 0.0885 - val_loss: 0.0903 - val_accuracy: 0.0988\nEpoch 5/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0901 - accuracy: 0.1136 - val_loss: 0.0898 - val_accuracy: 0.1272\nEpoch 6/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0896 - accuracy: 0.1479 - val_loss: 0.0894 - val_accuracy: 0.1676\nEpoch 7/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0892 - accuracy: 0.1949 - val_loss: 0.0890 - val_accuracy: 0.2266\nEpoch 8/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0889 - accuracy: 0.2535 - val_loss: 0.0887 - val_accuracy: 0.2852\nEpoch 9/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0885 - accuracy: 0.3045 - val_loss: 0.0883 - val_accuracy: 0.3300\nEpoch 10/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0882 - accuracy: 0.3427 - val_loss: 0.0880 - val_accuracy: 0.3629\nEpoch 11/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0878 - accuracy: 0.3656 - val_loss: 0.0877 - val_accuracy: 0.3828\nEpoch 12/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0875 - accuracy: 0.3803 - val_loss: 0.0873 - val_accuracy: 0.3963\nEpoch 13/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0872 - accuracy: 0.3909 - val_loss: 0.0870 - val_accuracy: 0.4074\nEpoch 14/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0869 - accuracy: 0.3991 - val_loss: 0.0867 - val_accuracy: 0.4136\nEpoch 15/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0865 - accuracy: 0.4042 - val_loss: 0.0863 - val_accuracy: 0.4157\nEpoch 16/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0862 - accuracy: 0.4081 - val_loss: 0.0860 - val_accuracy: 0.4183\nEpoch 17/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0858 - accuracy: 0.4114 - val_loss: 0.0856 - val_accuracy: 0.4212\nEpoch 18/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0855 - accuracy: 0.4138 - val_loss: 0.0853 - val_accuracy: 0.4223\nEpoch 19/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0851 - accuracy: 0.4149 - val_loss: 0.0849 - val_accuracy: 0.4232\nEpoch 20/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0848 - accuracy: 0.4174 - val_loss: 0.0845 - val_accuracy: 0.4233\nEpoch 21/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0844 - accuracy: 0.4168 - val_loss: 0.0841 - val_accuracy: 0.4255\nEpoch 22/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0840 - accuracy: 0.4189 - val_loss: 0.0837 - val_accuracy: 0.4263\nEpoch 23/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0836 - accuracy: 0.4211 - val_loss: 0.0833 - val_accuracy: 0.4263\nEpoch 24/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0832 - accuracy: 0.4231 - val_loss: 0.0829 - val_accuracy: 0.4286\nEpoch 25/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0828 - accuracy: 0.4249 - val_loss: 0.0825 - val_accuracy: 0.4291\nEpoch 26/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0824 - accuracy: 0.4273 - val_loss: 0.0821 - val_accuracy: 0.4292\nEpoch 27/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0820 - accuracy: 0.4295 - val_loss: 0.0817 - val_accuracy: 0.4303\nEpoch 28/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0816 - accuracy: 0.4312 - val_loss: 0.0812 - val_accuracy: 0.4325\nEpoch 29/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0811 - accuracy: 0.4327 - val_loss: 0.0808 - val_accuracy: 0.4358\nEpoch 30/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0807 - accuracy: 0.4365 - val_loss: 0.0803 - val_accuracy: 0.4382\nEpoch 31/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0802 - accuracy: 0.4388 - val_loss: 0.0799 - val_accuracy: 0.4408\nEpoch 32/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0798 - accuracy: 0.4411 - val_loss: 0.0794 - val_accuracy: 0.4443\nEpoch 33/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0793 - accuracy: 0.4446 - val_loss: 0.0789 - val_accuracy: 0.4469\nEpoch 34/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0788 - accuracy: 0.4490 - val_loss: 0.0784 - val_accuracy: 0.4501\nEpoch 35/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0783 - accuracy: 0.4513 - val_loss: 0.0779 - val_accuracy: 0.4536\nEpoch 36/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0778 - accuracy: 0.4556 - val_loss: 0.0774 - val_accuracy: 0.4573\nEpoch 37/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0773 - accuracy: 0.4598 - val_loss: 0.0769 - val_accuracy: 0.4614\nEpoch 38/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0768 - accuracy: 0.4641 - val_loss: 0.0764 - val_accuracy: 0.4667\nEpoch 39/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0763 - accuracy: 0.4683 - val_loss: 0.0759 - val_accuracy: 0.4713\nEpoch 40/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0758 - accuracy: 0.4724 - val_loss: 0.0754 - val_accuracy: 0.4762\nEpoch 41/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0753 - accuracy: 0.4781 - val_loss: 0.0749 - val_accuracy: 0.4811\nEpoch 42/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0748 - accuracy: 0.4831 - val_loss: 0.0744 - val_accuracy: 0.4855\nEpoch 43/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0743 - accuracy: 0.4878 - val_loss: 0.0738 - val_accuracy: 0.4906\nEpoch 44/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0738 - accuracy: 0.4927 - val_loss: 0.0733 - val_accuracy: 0.4953\nEpoch 45/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0732 - accuracy: 0.4972 - val_loss: 0.0728 - val_accuracy: 0.5015\nEpoch 46/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0727 - accuracy: 0.5016 - val_loss: 0.0723 - val_accuracy: 0.5068\nEpoch 47/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0722 - accuracy: 0.5067 - val_loss: 0.0717 - val_accuracy: 0.5123\nEpoch 48/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0717 - accuracy: 0.5116 - val_loss: 0.0712 - val_accuracy: 0.5162\nEpoch 49/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0712 - accuracy: 0.5166 - val_loss: 0.0707 - val_accuracy: 0.5216\nEpoch 50/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0706 - accuracy: 0.5215 - val_loss: 0.0701 - val_accuracy: 0.5255\nEpoch 51/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0701 - accuracy: 0.5260 - val_loss: 0.0696 - val_accuracy: 0.5304\nEpoch 52/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0696 - accuracy: 0.5308 - val_loss: 0.0691 - val_accuracy: 0.5343\nEpoch 53/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0691 - accuracy: 0.5362 - val_loss: 0.0686 - val_accuracy: 0.5390\nEpoch 54/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0686 - accuracy: 0.5417 - val_loss: 0.0681 - val_accuracy: 0.5457\nEpoch 55/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0681 - accuracy: 0.5465 - val_loss: 0.0676 - val_accuracy: 0.5492\nEpoch 56/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0676 - accuracy: 0.5513 - val_loss: 0.0671 - val_accuracy: 0.5544\nEpoch 57/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0671 - accuracy: 0.5566 - val_loss: 0.0665 - val_accuracy: 0.5600\nEpoch 58/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0666 - accuracy: 0.5620 - val_loss: 0.0660 - val_accuracy: 0.5655\nEpoch 59/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0661 - accuracy: 0.5680 - val_loss: 0.0655 - val_accuracy: 0.5710\nEpoch 60/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0656 - accuracy: 0.5726 - val_loss: 0.0651 - val_accuracy: 0.5773\nEpoch 61/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0651 - accuracy: 0.5775 - val_loss: 0.0646 - val_accuracy: 0.5826\nEpoch 62/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0646 - accuracy: 0.5822 - val_loss: 0.0641 - val_accuracy: 0.5877\nEpoch 63/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0642 - accuracy: 0.5877 - val_loss: 0.0636 - val_accuracy: 0.5929\nEpoch 64/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0637 - accuracy: 0.5922 - val_loss: 0.0631 - val_accuracy: 0.5996\nEpoch 65/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0632 - accuracy: 0.5966 - val_loss: 0.0626 - val_accuracy: 0.6045\nEpoch 66/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0628 - accuracy: 0.6014 - val_loss: 0.0622 - val_accuracy: 0.6090\nEpoch 67/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0623 - accuracy: 0.6064 - val_loss: 0.0617 - val_accuracy: 0.6137\nEpoch 68/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0618 - accuracy: 0.6104 - val_loss: 0.0612 - val_accuracy: 0.6176\nEpoch 69/100\n57728/60000 [===========================>..] - ETA: 0s - loss: 0.0614 - accuracy: 0.6160000/60000 [==============================] - 1s 18us/sample - loss: 0.0614 - accuracy: 0.6149 - val_loss: 0.0608 - val_accuracy: 0.6225\nEpoch 70/100\n59392/60000 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.6160000/60000 [==============================] - 1s 18us/sample - loss: 0.0609 - accuracy: 0.6192 - val_loss: 0.0603 - val_accuracy: 0.6259\nEpoch 71/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0605 - accuracy: 0.6229 - val_loss: 0.0599 - val_accuracy: 0.6293\nEpoch 72/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0600 - accuracy: 0.6268 - val_loss: 0.0594 - val_accuracy: 0.6327\nEpoch 73/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0596 - accuracy: 0.6306 - val_loss: 0.0590 - val_accuracy: 0.6350\nEpoch 74/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0592 - accuracy: 0.6343 - val_loss: 0.0586 - val_accuracy: 0.6393\nEpoch 75/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0588 - accuracy: 0.6381 - val_loss: 0.0581 - val_accuracy: 0.6425\nEpoch 76/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0583 - accuracy: 0.6414 - val_loss: 0.0577 - val_accuracy: 0.6458\nEpoch 77/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0579 - accuracy: 0.6445 - val_loss: 0.0573 - val_accuracy: 0.6488\nEpoch 78/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0575 - accuracy: 0.6479 - val_loss: 0.0568 - val_accuracy: 0.6513\nEpoch 79/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0571 - accuracy: 0.6504 - val_loss: 0.0564 - val_accuracy: 0.6545\nEpoch 80/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0567 - accuracy: 0.6532 - val_loss: 0.0560 - val_accuracy: 0.6586\nEpoch 81/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0563 - accuracy: 0.6559 - val_loss: 0.0556 - val_accuracy: 0.6607\nEpoch 82/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0559 - accuracy: 0.6590 - val_loss: 0.0552 - val_accuracy: 0.6625\nEpoch 83/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0555 - accuracy: 0.6612 - val_loss: 0.0548 - val_accuracy: 0.6652\nEpoch 84/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0551 - accuracy: 0.6644 - val_loss: 0.0544 - val_accuracy: 0.6675\nEpoch 85/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0547 - accuracy: 0.6665 - val_loss: 0.0540 - val_accuracy: 0.6707\nEpoch 86/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0543 - accuracy: 0.6699 - val_loss: 0.0536 - val_accuracy: 0.6729\nEpoch 87/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0539 - accuracy: 0.6717 - val_loss: 0.0532 - val_accuracy: 0.6754\nEpoch 88/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0535 - accuracy: 0.6744 - val_loss: 0.0528 - val_accuracy: 0.6767\nEpoch 89/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0532 - accuracy: 0.6766 - val_loss: 0.0525 - val_accuracy: 0.6791\nEpoch 90/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0528 - accuracy: 0.6794 - val_loss: 0.0521 - val_accuracy: 0.6820\nEpoch 91/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0524 - accuracy: 0.6815 - val_loss: 0.0517 - val_accuracy: 0.6848\nEpoch 92/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0521 - accuracy: 0.6838 - val_loss: 0.0513 - val_accuracy: 0.6871\nEpoch 93/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0517 - accuracy: 0.6861 - val_loss: 0.0510 - val_accuracy: 0.6904\nEpoch 94/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0514 - accuracy: 0.6884 - val_loss: 0.0506 - val_accuracy: 0.6934\nEpoch 95/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0510 - accuracy: 0.6908 - val_loss: 0.0503 - val_accuracy: 0.6966\nEpoch 96/100\n57984/60000 [===========================>..] - ETA: 0s - loss: 0.0506 - accuracy: 0.6960000/60000 [==============================] - 1s 16us/sample - loss: 0.0507 - accuracy: 0.6932 - val_loss: 0.0499 - val_accuracy: 0.6990\nEpoch 97/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0503 - accuracy: 0.6959 - val_loss: 0.0496 - val_accuracy: 0.7020\nEpoch 98/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0500 - accuracy: 0.6984 - val_loss: 0.0492 - val_accuracy: 0.7052\nEpoch 99/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0496 - accuracy: 0.7008 - val_loss: 0.0489 - val_accuracy: 0.7087\nEpoch 100/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0493 - accuracy: 0.7034 - val_loss: 0.0485 - val_accuracy: 0.7110\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1448a1d30c8>"
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "batch_size = 128\n",
    "nb_epoch = 100\n",
    "model.fit(x_train, y_train, batch_size= batch_size, epochs = nb_epoch, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_17 (Dense)             (None, 64)                50240     \n_________________________________________________________________\ndense_18 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 100 epochs, this basic network seems pretty good, with minimal optimization, the accuracy is "
   ]
  }
 ]
}