{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdlenvconda29b652f870674263985143dd5e5a7bc4",
   "display_name": "Python 3.7.6 64-bit ('DLENV': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First very simple Dense network, with no hidden layer.\n",
    "Start from here to improve the model in later iterations\n",
    "2 layers:\n",
    "- Input: 64 units, sigmoid\n",
    "- Output: 10 units, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy: Numeric library\n",
    "import numpy as np \n",
    "#graphics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#tensorflow: use some TF tools\n",
    "import tensorflow as tf\n",
    "#Keras: Deep learning API. In TF 2.x, it is included in TF\n",
    "from tensorflow import keras\n",
    "#Import Dense layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "#Optimizers: SGD (Stochastic Gradien Descent)\n",
    "#from tensorflow.keras.optimizers import SGD as sgd\n",
    "\n",
    "#import data set MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.4945749307698868\n"
    }
   ],
   "source": [
    "#TF\n",
    "print(np.random.uniform())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import MNIST data set\n",
    "60000 training examples\n",
    "10000 validation examples\n",
    "1 example = 28 * 28 matrix (image with 28 * 28 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 28, 28)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000,)\n"
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(28, 28)\n"
    }
   ],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[5 0 4 ... 5 6 8]\n60000\n"
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(10000, 28, 28)\n(10000,)\n"
    }
   ],
   "source": [
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process & Prepare data\n",
    "Flattening Input data:\n",
    "Input data (x_train[i]) should be a vector of real values\n",
    "- From shape (60000, 28, 28) to shape (60000, 28 * 28)\n",
    "- Convert to float32 (default is uint8, which python will convert to float64) (flaot 32 will take less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.reshape(60000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numpy reshape\n",
    "x_train = np.reshape(x_train, (60000, 28 * 28)).astype('float32')\n",
    "x_valid = np.reshape(x_valid, (10000, 28 * 28)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 784)\n(10000, 784)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare Data (2)\n",
    "divide by 255, so the values will range from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train)\n",
    "x_train /=  255\n",
    "x_valid /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare labels (y_train and y_valid)\n",
    "y_train[i] is given as a number (0, 9). We have 10 possible values. \n",
    "Convert to one-hot format:\n",
    "0 => [1, 0, 0, 0, 0,0, 0,0, 0,0]\n",
    "1 => [0, 1, 0, 0, 0,0, 0,0, 0,0]\n",
    "9 => [0, 0, 0, 0, 0,0, 0,0, 0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n7\n[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "print(y_train[0])\n",
    "\n",
    "print(y_valid[0])\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
    "print(y_valid[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Neural Network Architecture\n",
    "Using Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_11\", \"layers\": []}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential: model of type sequential (layer n can pass information only to layer n+1)\n",
    "model = Sequential()\n",
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x00000144B170EFC8>\n"
    }
   ],
   "source": [
    "#Define activations\n",
    "sigmoid = keras.activations.sigmoid\n",
    "softmax = keras.activations.softmax\n",
    "\n",
    "#define loss function\n",
    "loss = keras.losses.mean_squared_error\n",
    "\n",
    "#define metrics\n",
    "metrics = [keras.metrics.Accuracy()]\n",
    "\n",
    "#define optimizer\n",
    "sgd=keras.optimizers.SGD()\n",
    "print(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Input layer\n",
    "inputSize = 28 * 28 # size of input vector\n",
    "inputUnits = 64 #Number of input layer units (artificial neuron)\n",
    "inputLayer = Dense(inputUnits, activation=  sigmoid, input_shape=(inputSize,))\n",
    "model.add(inputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Output layer\n",
    " \n",
    "outputUnits = 10 #Number of output layer units (artificial neuron)\n",
    "# output shape will be inferred\n",
    "outputLayer = Dense(outputUnits, activation=  softmax)\n",
    "model.add(outputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile Model\n",
    "model.compile(loss=loss, \n",
    "         optimizer=sgd,\n",
    "         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_15 (Dense)             (None, 64)                50240     \n_________________________________________________________________\ndense_16 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 1s 25us/sample - loss: 0.0926 - accuracy: 0.1543 - val_loss: 0.0922 - val_accuracy: 0.1598\nEpoch 2/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0917 - accuracy: 0.1734 - val_loss: 0.0913 - val_accuracy: 0.1772\nEpoch 3/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0909 - accuracy: 0.1898 - val_loss: 0.0906 - val_accuracy: 0.2035\nEpoch 4/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0903 - accuracy: 0.2382 - val_loss: 0.0900 - val_accuracy: 0.2720\nEpoch 5/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0897 - accuracy: 0.2889 - val_loss: 0.0895 - val_accuracy: 0.3070\nEpoch 6/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0893 - accuracy: 0.3074 - val_loss: 0.0891 - val_accuracy: 0.3190\nEpoch 7/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0888 - accuracy: 0.3137 - val_loss: 0.0887 - val_accuracy: 0.3228\nEpoch 8/10\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0884 - accuracy: 0.3169 - val_loss: 0.0883 - val_accuracy: 0.3255\nEpoch 9/10\n18688/60000 [========>.....................] - ETA: 0s - loss: 0.0883 - accuracy: 0.3168"
    }
   ],
   "source": [
    "# Train\n",
    "batch_size = 128\n",
    "nb_epoch = 10\n",
    "model.fit(x_train, y_train, batch_size= batch_size, epochs = nb_epoch, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}