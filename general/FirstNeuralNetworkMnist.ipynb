{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitdlenvconda29b652f870674263985143dd5e5a7bc4",
   "display_name": "Python 3.7.6 64-bit ('DLENV': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First very simple Dense network, with no hidden layer.\n",
    "Start from here to improve the model in later iterations\n",
    "2 layers:\n",
    "- Input: 64 units, sigmoid\n",
    "- Output: 10 units, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy: Numeric library\n",
    "import numpy as np \n",
    "#graphics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#tensorflow: use some TF tools\n",
    "import tensorflow as tf\n",
    "#Keras: Deep learning API. In TF 2.x, it is included in TF\n",
    "from tensorflow import keras\n",
    "#Import Dense layer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "#Optimizers: SGD (Stochastic Gradien Descent)\n",
    "#from tensorflow.keras.optimizers import SGD as sgd\n",
    "\n",
    "#import data set MNIST\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some verifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.5455288109712575\n"
    }
   ],
   "source": [
    "#TF\n",
    "print(np.random.uniform())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import MNIST data set\n",
    "60000 training examples\n",
    "10000 validation examples\n",
    "1 example = 28 * 28 matrix (image with 28 * 28 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 28, 28)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000,)\n"
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(28, 28)\n"
    }
   ],
   "source": [
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[5 0 4 ... 5 6 8]\n60000\n"
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(10000, 28, 28)\n(10000,)\n"
    }
   ],
   "source": [
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Process & Prepare data\n",
    "Flattening Input data:\n",
    "Input data (x_train[i]) should be a vector of real values\n",
    "- From shape (60000, 28, 28) to shape (60000, 28 * 28)\n",
    "- Convert to float32 (default is uint8, which python will convert to float64) (flaot 32 will take less memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.reshape(60000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numpy reshape\n",
    "x_train = np.reshape(x_train, (60000, 28 * 28)).astype('float32')\n",
    "x_valid = np.reshape(x_valid, (10000, 28 * 28)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(60000, 784)\n(10000, 784)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare Data (2)\n",
    "divide by 255, so the values will range from 0 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train)\n",
    "x_train /=  255\n",
    "x_valid /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepare labels (y_train and y_valid)\n",
    "y_train[i] is given as a number (0, 9). We have 10 possible values. \n",
    "Convert to one-hot format:\n",
    "0 => [1, 0, 0, 0, 0,0, 0,0, 0,0]\n",
    "1 => [0, 1, 0, 0, 0,0, 0,0, 0,0]\n",
    "9 => [0, 0, 0, 0, 0,0, 0,0, 0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n7\n[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "print(y_train[0])\n",
    "\n",
    "print(y_valid[0])\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
    "print(y_valid[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Neural Network Architecture\n",
    "Using Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_13\", \"layers\": []}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}'"
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential: model of type sequential (layer n can pass information only to layer n+1)\n",
    "model = Sequential()\n",
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x00000144DFC94088>\n"
    }
   ],
   "source": [
    "#Define activations\n",
    "sigmoid = keras.activations.sigmoid\n",
    "softmax = keras.activations.softmax\n",
    "\n",
    "#define loss function\n",
    "loss = keras.losses.mean_squared_error\n",
    "\n",
    "#define metrics\n",
    "metrics = [keras.metrics.Accuracy()]\n",
    "\n",
    "#define optimizer\n",
    "sgd=keras.optimizers.SGD()\n",
    "print(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Input layer\n",
    "inputSize = 28 * 28 # size of input vector\n",
    "inputUnits = 64 #Number of input layer units (artificial neuron)\n",
    "inputLayer = Dense(inputUnits, activation=  sigmoid, input_shape=(inputSize,))\n",
    "model.add(inputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Output layer\n",
    " \n",
    "outputUnits = 10 #Number of output layer units (artificial neuron)\n",
    "# output shape will be inferred\n",
    "outputLayer = Dense(outputUnits, activation=  softmax)\n",
    "model.add(outputLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile Model\n",
    "model.compile(loss=loss, \n",
    "         optimizer=sgd,\n",
    "         metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_19 (Dense)             (None, 64)                50240     \n_________________________________________________________________\ndense_20 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/100\n60000/60000 [==============================] - 2s 33us/sample - loss: 0.0912 - accuracy: 0.1137 - val_loss: 0.0908 - val_accuracy: 0.1364\nEpoch 2/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0905 - accuracy: 0.1599 - val_loss: 0.0902 - val_accuracy: 0.1867\nEpoch 3/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0900 - accuracy: 0.2034 - val_loss: 0.0898 - val_accuracy: 0.2149\nEpoch 4/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0896 - accuracy: 0.2226 - val_loss: 0.0894 - val_accuracy: 0.2301\nEpoch 5/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0892 - accuracy: 0.2343 - val_loss: 0.0890 - val_accuracy: 0.2409\nEpoch 6/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0889 - accuracy: 0.2443 - val_loss: 0.0887 - val_accuracy: 0.2546\nEpoch 7/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0885 - accuracy: 0.2583 - val_loss: 0.0883 - val_accuracy: 0.2706\nEpoch 8/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0882 - accuracy: 0.2732 - val_loss: 0.0879 - val_accuracy: 0.2879\nEpoch 9/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0878 - accuracy: 0.2914 - val_loss: 0.0876 - val_accuracy: 0.3063\nEpoch 10/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0875 - accuracy: 0.3086 - val_loss: 0.0873 - val_accuracy: 0.3245\nEpoch 11/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0871 - accuracy: 0.3223 - val_loss: 0.0869 - val_accuracy: 0.3384\nEpoch 12/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0868 - accuracy: 0.3365 - val_loss: 0.0866 - val_accuracy: 0.3506\nEpoch 13/100\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.0864 - accuracy: 0.3455 - val_loss: 0.0862 - val_accuracy: 0.3593\nEpoch 14/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0861 - accuracy: 0.3515 - val_loss: 0.0858 - val_accuracy: 0.3644\nEpoch 15/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0857 - accuracy: 0.3559 - val_loss: 0.0855 - val_accuracy: 0.3671\nEpoch 16/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0854 - accuracy: 0.3577 - val_loss: 0.0851 - val_accuracy: 0.3693\nEpoch 17/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0850 - accuracy: 0.3586 - val_loss: 0.0847 - val_accuracy: 0.3713\nEpoch 18/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0846 - accuracy: 0.3600 - val_loss: 0.0843 - val_accuracy: 0.3715\nEpoch 19/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0843 - accuracy: 0.3604 - val_loss: 0.0840 - val_accuracy: 0.3713\nEpoch 20/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0839 - accuracy: 0.3604 - val_loss: 0.0836 - val_accuracy: 0.3711\nEpoch 21/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0835 - accuracy: 0.3617 - val_loss: 0.0832 - val_accuracy: 0.3720\nEpoch 22/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0831 - accuracy: 0.3617 - val_loss: 0.0828 - val_accuracy: 0.3732\nEpoch 23/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0827 - accuracy: 0.3652 - val_loss: 0.0824 - val_accuracy: 0.3758\nEpoch 24/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0823 - accuracy: 0.3675 - val_loss: 0.0819 - val_accuracy: 0.3783\nEpoch 25/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0819 - accuracy: 0.3686 - val_loss: 0.0815 - val_accuracy: 0.3804\nEpoch 26/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0815 - accuracy: 0.3729 - val_loss: 0.0811 - val_accuracy: 0.3828\nEpoch 27/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0811 - accuracy: 0.3762 - val_loss: 0.0807 - val_accuracy: 0.3882\nEpoch 28/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0807 - accuracy: 0.3814 - val_loss: 0.0802 - val_accuracy: 0.3920\nEpoch 29/100\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.0802 - accuracy: 0.3871 - val_loss: 0.0798 - val_accuracy: 0.3974\nEpoch 30/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0798 - accuracy: 0.3910 - val_loss: 0.0794 - val_accuracy: 0.4030\nEpoch 31/100\n60000/60000 [==============================] - 1s 15us/sample - loss: 0.0794 - accuracy: 0.3983 - val_loss: 0.0789 - val_accuracy: 0.4094\nEpoch 32/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0789 - accuracy: 0.4044 - val_loss: 0.0785 - val_accuracy: 0.4170\nEpoch 33/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0785 - accuracy: 0.4123 - val_loss: 0.0780 - val_accuracy: 0.4229\nEpoch 34/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0780 - accuracy: 0.4191 - val_loss: 0.0775 - val_accuracy: 0.4306\nEpoch 35/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0776 - accuracy: 0.4272 - val_loss: 0.0771 - val_accuracy: 0.4380\nEpoch 36/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0771 - accuracy: 0.4369 - val_loss: 0.0766 - val_accuracy: 0.4451\nEpoch 37/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0766 - accuracy: 0.4440 - val_loss: 0.0761 - val_accuracy: 0.4547\nEpoch 38/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0762 - accuracy: 0.4517 - val_loss: 0.0756 - val_accuracy: 0.4641\nEpoch 39/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0757 - accuracy: 0.4602 - val_loss: 0.0752 - val_accuracy: 0.4739\nEpoch 40/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0752 - accuracy: 0.4685 - val_loss: 0.0747 - val_accuracy: 0.4812\nEpoch 41/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0747 - accuracy: 0.4781 - val_loss: 0.0742 - val_accuracy: 0.4899\nEpoch 42/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0743 - accuracy: 0.4867 - val_loss: 0.0737 - val_accuracy: 0.4999\nEpoch 43/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0738 - accuracy: 0.4956 - val_loss: 0.0732 - val_accuracy: 0.5102\nEpoch 44/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0733 - accuracy: 0.5034 - val_loss: 0.0727 - val_accuracy: 0.5174\nEpoch 45/100\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.0728 - accuracy: 0.5120 - val_loss: 0.0722 - val_accuracy: 0.5257\nEpoch 46/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0723 - accuracy: 0.5211 - val_loss: 0.0717 - val_accuracy: 0.5335\nEpoch 47/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0718 - accuracy: 0.5288 - val_loss: 0.0712 - val_accuracy: 0.5418\nEpoch 48/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0713 - accuracy: 0.5365 - val_loss: 0.0707 - val_accuracy: 0.5497\nEpoch 49/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0709 - accuracy: 0.5441 - val_loss: 0.0702 - val_accuracy: 0.5581\nEpoch 50/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0704 - accuracy: 0.5523 - val_loss: 0.0697 - val_accuracy: 0.5664\nEpoch 51/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0699 - accuracy: 0.5594 - val_loss: 0.0692 - val_accuracy: 0.5728\nEpoch 52/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0694 - accuracy: 0.5662 - val_loss: 0.0687 - val_accuracy: 0.5798\nEpoch 53/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0689 - accuracy: 0.5721 - val_loss: 0.0682 - val_accuracy: 0.5861\nEpoch 54/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0684 - accuracy: 0.5780 - val_loss: 0.0677 - val_accuracy: 0.5930\nEpoch 55/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0679 - accuracy: 0.5848 - val_loss: 0.0672 - val_accuracy: 0.6006\nEpoch 56/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0674 - accuracy: 0.5910 - val_loss: 0.0667 - val_accuracy: 0.6058\nEpoch 57/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0669 - accuracy: 0.5965 - val_loss: 0.0662 - val_accuracy: 0.6101\nEpoch 58/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0664 - accuracy: 0.6018 - val_loss: 0.0657 - val_accuracy: 0.6158\nEpoch 59/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0659 - accuracy: 0.6080 - val_loss: 0.0652 - val_accuracy: 0.6218\nEpoch 60/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0654 - accuracy: 0.6128 - val_loss: 0.0647 - val_accuracy: 0.6261\nEpoch 61/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0649 - accuracy: 0.6181 - val_loss: 0.0642 - val_accuracy: 0.6306\nEpoch 62/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0645 - accuracy: 0.6229 - val_loss: 0.0637 - val_accuracy: 0.6351\nEpoch 63/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0640 - accuracy: 0.6281 - val_loss: 0.0632 - val_accuracy: 0.6385\nEpoch 64/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0635 - accuracy: 0.6325 - val_loss: 0.0627 - val_accuracy: 0.6420\nEpoch 65/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0630 - accuracy: 0.6369 - val_loss: 0.0622 - val_accuracy: 0.6447\nEpoch 66/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0625 - accuracy: 0.6406 - val_loss: 0.0617 - val_accuracy: 0.6488\nEpoch 67/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0620 - accuracy: 0.6446 - val_loss: 0.0613 - val_accuracy: 0.6524\nEpoch 68/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0616 - accuracy: 0.6482 - val_loss: 0.0608 - val_accuracy: 0.6558\nEpoch 69/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0611 - accuracy: 0.6520 - val_loss: 0.0603 - val_accuracy: 0.6586\nEpoch 70/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0606 - accuracy: 0.6558 - val_loss: 0.0598 - val_accuracy: 0.6626\nEpoch 71/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0601 - accuracy: 0.6593 - val_loss: 0.0593 - val_accuracy: 0.6650\nEpoch 72/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0597 - accuracy: 0.6625 - val_loss: 0.0588 - val_accuracy: 0.6689\nEpoch 73/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0592 - accuracy: 0.6659 - val_loss: 0.0584 - val_accuracy: 0.6717\nEpoch 74/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0587 - accuracy: 0.6697 - val_loss: 0.0579 - val_accuracy: 0.6747\nEpoch 75/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0583 - accuracy: 0.6723 - val_loss: 0.0574 - val_accuracy: 0.6774\nEpoch 76/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0578 - accuracy: 0.6750 - val_loss: 0.0569 - val_accuracy: 0.6814\nEpoch 77/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0573 - accuracy: 0.6777 - val_loss: 0.0565 - val_accuracy: 0.6844\nEpoch 78/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0569 - accuracy: 0.6803 - val_loss: 0.0560 - val_accuracy: 0.6873\nEpoch 79/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0564 - accuracy: 0.6834 - val_loss: 0.0556 - val_accuracy: 0.6903\nEpoch 80/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0560 - accuracy: 0.6861 - val_loss: 0.0551 - val_accuracy: 0.6943\nEpoch 81/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0555 - accuracy: 0.6891 - val_loss: 0.0547 - val_accuracy: 0.6970\nEpoch 82/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0551 - accuracy: 0.6915 - val_loss: 0.0542 - val_accuracy: 0.7000\nEpoch 83/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0546 - accuracy: 0.6944 - val_loss: 0.0538 - val_accuracy: 0.7032\nEpoch 84/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0542 - accuracy: 0.6974 - val_loss: 0.0533 - val_accuracy: 0.7060\nEpoch 85/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0538 - accuracy: 0.6995 - val_loss: 0.0529 - val_accuracy: 0.7090\nEpoch 86/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0534 - accuracy: 0.7020 - val_loss: 0.0525 - val_accuracy: 0.7121\nEpoch 87/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0529 - accuracy: 0.7047 - val_loss: 0.0520 - val_accuracy: 0.7137\nEpoch 88/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0525 - accuracy: 0.7073 - val_loss: 0.0516 - val_accuracy: 0.7171\nEpoch 89/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0521 - accuracy: 0.7102 - val_loss: 0.0512 - val_accuracy: 0.7192\nEpoch 90/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0517 - accuracy: 0.7125 - val_loss: 0.0508 - val_accuracy: 0.7214\nEpoch 91/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0513 - accuracy: 0.7152 - val_loss: 0.0504 - val_accuracy: 0.7240\nEpoch 92/100\n60000/60000 [==============================] - 1s 20us/sample - loss: 0.0509 - accuracy: 0.7177 - val_loss: 0.0500 - val_accuracy: 0.7276\nEpoch 93/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0505 - accuracy: 0.7200 - val_loss: 0.0496 - val_accuracy: 0.7311\nEpoch 94/100\n60000/60000 [==============================] - 1s 16us/sample - loss: 0.0501 - accuracy: 0.7224 - val_loss: 0.0492 - val_accuracy: 0.7325\nEpoch 95/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0497 - accuracy: 0.7247 - val_loss: 0.0488 - val_accuracy: 0.7343\nEpoch 96/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0493 - accuracy: 0.7273 - val_loss: 0.0484 - val_accuracy: 0.7372\nEpoch 97/100\n60000/60000 [==============================] - 1s 19us/sample - loss: 0.0490 - accuracy: 0.7303 - val_loss: 0.0480 - val_accuracy: 0.7394\nEpoch 98/100\n60000/60000 [==============================] - 1s 18us/sample - loss: 0.0486 - accuracy: 0.7326 - val_loss: 0.0476 - val_accuracy: 0.7410\nEpoch 99/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0482 - accuracy: 0.7351 - val_loss: 0.0473 - val_accuracy: 0.7443\nEpoch 100/100\n60000/60000 [==============================] - 1s 17us/sample - loss: 0.0478 - accuracy: 0.7372 - val_loss: 0.0469 - val_accuracy: 0.7474\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x144dfc19708>"
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "batch_size = 128\n",
    "nb_epoch = 100\n",
    "model.fit(x_train, y_train, batch_size= batch_size, epochs = nb_epoch, verbose=1, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_19 (Dense)             (None, 64)                50240     \n_________________________________________________________________\ndense_20 (Dense)             (None, 10)                650       \n=================================================================\nTotal params: 50,890\nTrainable params: 50,890\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "With 100 epochs, this basic network seems pretty good, with minimal optimization, the accuracy is above 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "End"
   ]
  }
 ]
}